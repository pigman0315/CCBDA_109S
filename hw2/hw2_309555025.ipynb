{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "762668b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import csv\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "# Device configuration\n",
    "torch.cuda.set_device(0)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a923ce99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockPrediction:\n",
    "    def __init__(self,filename):\n",
    "        # read spcific company file\n",
    "        file = open(FILE_PREFIX+filename)\n",
    "        rows = csv.reader(file)\n",
    "        next(rows) # remove header\n",
    "        dataset = []\n",
    "        for row in rows:\n",
    "            dataset.append(row)\n",
    "        self.dataset = np.array(dataset)\n",
    "        file.close()\n",
    "        # read Nasdaq index\n",
    "        file = open(FILE_PREFIX+'^IXIC.csv')\n",
    "        rows = csv.reader(file)\n",
    "        next(rows) # remove header\n",
    "        nasdaq_data = []\n",
    "        for row in rows:\n",
    "            nasdaq_data.append(row)\n",
    "        self.nasdaq_data = np.array(nasdaq_data)\n",
    "        file.close()\n",
    "        #print(\"Data number:\",len(dataset))\n",
    "        #print(\"Data number2:\",len(nasdaq_data))\n",
    "    def getFeatures(self):\n",
    "        single_day_features = self.dataset[:,1:]\n",
    "        #single_day_features = self.dataset[:,5:6]\n",
    "        single_day_features = np.append(single_day_features,self.nasdaq_data[:,5].reshape(len(self.nasdaq_data[:,5]),1),axis = 1)\n",
    "        single_day_features =  single_day_features.astype(np.double)\n",
    "        #for i in range(1,7):\n",
    "            #single_day_features = np.append(single_day_features,self.nasdaq_data[:,i].reshape(len(self.nasdaq_data[:,i]),1),axis = 1)\n",
    "        # Normalization\n",
    "        for i in range(NUM_FEATURES):\n",
    "            single_day_features[:,i] = (single_day_features[:,i] - np.min(single_day_features[:,i])) / (np.max(single_day_features[:,i])-np.min(single_day_features[:,i]))\n",
    "        single_day_features = (single_day_features - np.min(single_day_features)) / (np.max(single_day_features)-np.min(single_day_features))\n",
    "        # get features\n",
    "        self.features = []\n",
    "        for i in range(len(self.dataset)-SEQ_LENGTH+1):\n",
    "            self.features.append(single_day_features[i:i+SEQ_LENGTH].reshape(NUM_FEATURES*SEQ_LENGTH))\n",
    "        \n",
    "        self.features = np.array(self.features)\n",
    "        self.predict_feature = self.features[-1,:].copy()\n",
    "        self.features = self.features[:-1,:]\n",
    "    def getLabels(self):\n",
    "        self.labels = self.dataset[SEQ_LENGTH:,5]\n",
    "        self.labels = self.labels.astype(np.double)\n",
    "        # normalization\n",
    "        self.label_max = np.max(self.labels)\n",
    "        self.label_min = np.min(self.labels)\n",
    "        self.labels = (self.labels - np.min(self.labels))/(np.max(self.labels)-np.min(self.labels))\n",
    "        self.last_label = self.labels[-1].copy()\n",
    "#     def getLabels(self):\n",
    "#         adj_close = self.dataset[SEQ_LENGTH-1:,5]\n",
    "#         adj_close = adj_close.astype(np.double)\n",
    "#         self.labels = []\n",
    "#         for i in range(1,len(adj_close)):\n",
    "#             if((abs(adj_close[i]-adj_close[i-1])/adj_close[i-1]) > 0.015):\n",
    "#                 if(adj_close[i] > adj_close[i-1]):\n",
    "#                     self.labels.append(0)\n",
    "#                 else:\n",
    "#                     self.labels.append(2)\n",
    "#             else:\n",
    "#                 self.labels.append(1)\n",
    "#         self.labels = np.array(self.labels)\n",
    "#         self.labels = self.labels.astype(np.long)\n",
    "\n",
    "    def shuffleData(self):\n",
    "        data = np.append(self.features,self.labels.reshape(len(self.labels),1),axis=1)\n",
    "        #np.random.shuffle(data[:-TEST_SIZE])\n",
    "        np.random.shuffle(data[:])\n",
    "        self.features = data[:,:NUM_FEATURES*SEQ_LENGTH]\n",
    "        self.labels = data[:,NUM_FEATURES*SEQ_LENGTH]\n",
    "    def splitTrainTest(self,test_size):\n",
    "        self.train_features = self.features[:-test_size]\n",
    "        self.test_features = self.features[-test_size:]\n",
    "        self.train_labels = self.labels[:-test_size]\n",
    "        self.test_labels = self.labels[-test_size:]\n",
    "    def toTensor(self):\n",
    "        self.train_features_ts = torch.from_numpy(self.train_features)\n",
    "        self.test_features_ts = torch.from_numpy(self.test_features)\n",
    "        self.train_labels_ts = torch.from_numpy(self.train_labels)\n",
    "        self.test_labels_ts = torch.from_numpy(self.test_labels)\n",
    "    def train(self):\n",
    "        self.model = LSTM(INPUT_SIZE, HIDDEN_SIZE, NUM_LAYERS)\n",
    "        self.model = self.model.cuda()\n",
    "        \n",
    "        # Loss and optimizer\n",
    "        loss_func = nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=LEARNING_RATE)\n",
    "        \n",
    "        # Prepare data loader\n",
    "        train_dataset = torch.utils.data.TensorDataset(self.train_features_ts,self.train_labels_ts)\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "        test_dataset = torch.utils.data.TensorDataset(self.test_features_ts,self.test_labels_ts)\n",
    "        test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=TEST_SIZE, shuffle=False)\n",
    "        \n",
    "       \n",
    "        self.train_loss_list = []\n",
    "        self.test_loss_list = []\n",
    "        train_loss = 0\n",
    "        for ep in range(NUM_EPOCHS):\n",
    "            # Train the model\n",
    "            for i, (data, labels) in enumerate(train_loader):\n",
    "                # resize\n",
    "                data = Variable(data.view(-1, SEQ_LENGTH, INPUT_SIZE).float().cuda())\n",
    "                labels = Variable(labels.view(len(labels),1).float().cuda())\n",
    "                \n",
    "                # forward pass\n",
    "                outputs = self.model(data)\n",
    "                train_loss = loss_func(outputs,labels)\n",
    "                \n",
    "                # backward and optimize\n",
    "                optimizer.zero_grad() # clear gradient\n",
    "                train_loss.backward() # backpropagation to get gradient\n",
    "                optimizer.step() # optimize parameters\n",
    "                \n",
    "                # output result\n",
    "                #print('Epoch:',ep+1,', Step:',i+1,', Loss:', train_loss.item())\n",
    "                \n",
    "            self.train_loss_list.append(train_loss.item())\n",
    "            \n",
    "            # Test the model\n",
    "            test_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for data , labels in test_loader:\n",
    "                    # resize\n",
    "                    data = data.view(-1, SEQ_LENGTH, INPUT_SIZE).float().cuda()\n",
    "                    labels = labels.view(len(labels),1).float().cuda()\n",
    "\n",
    "                    # forward pass\n",
    "                    outputs = self.model(data)\n",
    "                    test_loss = loss_func(outputs,labels)\n",
    "\n",
    "                    # record loss\n",
    "                    self.test_loss_list.append(test_loss.cpu().item())\n",
    "    def test(self):\n",
    "        # Prepare data loader\n",
    "        test_dataset = torch.utils.data.TensorDataset(self.test_features_ts,self.test_labels_ts)\n",
    "        test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "        \n",
    "        # Test the model\n",
    "        # In test phase, we don't need to compute gradients (for memory efficient)\n",
    "        with torch.no_grad():\n",
    "            n_correct = 0\n",
    "            n_samples = 0\n",
    "            for data , labels in test_loader:\n",
    "                # resize\n",
    "                data = data.view(-1, SEQ_LENGTH, INPUT_SIZE).cuda()\n",
    "                labels = labels.float().cpu()\n",
    "                # Forward pass\n",
    "                outputs = self.model(data.float())\n",
    "                \n",
    "                # calculate reuslt\n",
    "                n_samples += labels.size(0)\n",
    "                labels = labels.item()\n",
    "                if(abs(outputs.cpu().item()-labels)/(labels+0.00000001) < 0.015):\n",
    "                    n_correct += 1\n",
    "                #print(outputs.cpu().item(),labels)\n",
    "            accuracy = 100.0 * n_correct / n_samples\n",
    "            print(\"Accuracy(in +- 1.5%):\",accuracy,\"%\")\n",
    "    def predict(self):\n",
    "        # get output\n",
    "        with torch.no_grad():\n",
    "            #print(self.predict_feature)\n",
    "            data = torch.from_numpy(self.predict_feature).cuda()\n",
    "            # resize\n",
    "            data = data.view(-1, SEQ_LENGTH, INPUT_SIZE)\n",
    "            #print(data)\n",
    "            # Forward pass\n",
    "            output = self.model(data.float())\n",
    "            output = output*(self.label_max-self.label_min)+self.label_min\n",
    "            output = output.item()\n",
    "            past = self.last_label\n",
    "            past = past*(self.label_max-self.label_min)+self.label_min\n",
    "            print(output,past,abs(output-past)/past,end=', ')\n",
    "            if(abs(output-past)/past > ACC):\n",
    "                if(output > past):\n",
    "                    ans = 0\n",
    "                else:\n",
    "                    ans = 2\n",
    "            else:\n",
    "                ans = 1\n",
    "        #print(ans,end=',')\n",
    "        print(ans)\n",
    "        return ans\n",
    "    def testResult(self):\n",
    "        #\n",
    "        self.predict_list = []\n",
    "        self.now_list = []\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            for i in range(1,TEST_SIZE):\n",
    "                data = self.test_features_ts[i]\n",
    "                # resize\n",
    "                data = data.view(-1, SEQ_LENGTH, INPUT_SIZE).cuda()\n",
    "\n",
    "                # Forward pass\n",
    "                output = self.model(data.float()).item()\n",
    "\n",
    "                # restore output to normal value\n",
    "                #output = output*(self.label_max-self.label_min)+self.label_min\n",
    "                self.predict_list.append(output)\n",
    "                now = self.test_labels[i]#*(self.label_max-self.label_min)+self.label_min\n",
    "                self.now_list.append(now)\n",
    "                past = self.test_labels[i-1]#*(self.label_max-self.label_min)+self.label_min\n",
    "                r1 = -1\n",
    "                r2 = -2\n",
    "                if((abs(output- past)/(past+0.000000001)) > 0.015):\n",
    "                    if(output >  past):\n",
    "                        #print('0', end = ',')\n",
    "                        r1 = 0\n",
    "                    else:\n",
    "                        #print('2', end = ',')\n",
    "                        r1 = 2\n",
    "                else:\n",
    "                    #print('1', end = ',')\n",
    "                    r1 = 1\n",
    "                if((abs(now-past)/(past+0.000000001)) > 0.015):\n",
    "                    if(now > past):\n",
    "                        #print('0')\n",
    "                        r2 = 0\n",
    "                    else:\n",
    "                        #print('2')\n",
    "                        r2 = 2\n",
    "                else:\n",
    "                    #print('1')\n",
    "                    r2 = 1\n",
    "                if(r2 == r1):\n",
    "                    correct += 1\n",
    "                #print(output, now, past,sep=',')\n",
    "            print(\"Accuracy: \", correct/(TEST_SIZE-1))\n",
    "        #\n",
    "        plt.plot(self.predict_list,label=\"predict\")\n",
    "        plt.plot(self.now_list,label=\"true\")\n",
    "        plt.legend(loc='best')\n",
    "        plt.show()\n",
    "    def plotGraph(self):\n",
    "        plt.plot(self.train_loss_list,label=\"train\")\n",
    "        plt.plot(self.test_loss_list,label=\"test\")  \n",
    "        plt.title(\"Average Loss\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"MSE Loss\")\n",
    "        plt.legend(loc='best')\n",
    "        plt.show()\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, INPUT_SIZE, HIDDEN_SIZE, NUM_LAYERS):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.num_layers = NUM_LAYERS\n",
    "        self.hidden_size = HIDDEN_SIZE\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=INPUT_SIZE,\n",
    "            hidden_size=HIDDEN_SIZE,\n",
    "            num_layers=NUM_LAYERS,\n",
    "            batch_first = True, # use batch size as first dimension, x -> (batch_size, seq, input_size)\n",
    "            dropout = DROP_OUT\n",
    "        )\n",
    "        self.fc = nn.Linear(HIDDEN_SIZE, 1) # fully connected\n",
    "\n",
    "    def forward(self, x ):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).cuda()\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).cuda()\n",
    "        \n",
    "        out, _ = self.lstm(x,(h0,c0))\n",
    "        out = out[:,-1,:]\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a8d55a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy(in +- 1.5%): 19.444444444444443 %\n",
      "58.13196563720703 57.189999 0.01647082800625737, 0\n",
      "Accuracy(in +- 1.5%): 24.72222222222222 %\n",
      "77.44417572021484 77.889999 0.0057237551098846375, 1\n",
      "Accuracy(in +- 1.5%): 30.27777777777778 %\n",
      "52.191680908203125 52.439999 0.004735280254236375, 1\n",
      "Accuracy(in +- 1.5%): 32.5 %\n",
      "131.0566864013672 129.740005 0.010148615312348655, 1\n",
      "Accuracy(in +- 1.5%): 19.444444444444443 %\n",
      "83.67858123779297 84.800003 0.013224312765732273, 1\n",
      "Accuracy(in +- 1.5%): 26.944444444444443 %\n",
      "578.0801391601562 580.919983 0.0048885284082984485, 1\n",
      "Accuracy(in +- 1.5%): 15.833333333333334 %\n",
      "133.38418579101562 136.0 0.01923392800723805, 2\n",
      "Accuracy(in +- 1.5%): 6.666666666666667 %\n",
      "3192.39990234375 3306.370117 0.03446989012822908, 2\n",
      "Accuracy(in +- 1.5%): 33.05555555555556 %\n",
      "508.4749755859375 499.549988 0.017866055050205536, 0\n",
      "Accuracy(in +- 1.5%): 30.27777777777778 %\n",
      "316.54248046875 320.019989 0.01086653537523248, 1\n",
      "Accuracy(in +- 1.5%): 12.777777777777779 %\n",
      "2323.72021484375 2381.350098 0.024200508444621776, 2\n",
      "Accuracy(in +- 1.5%): 31.944444444444443 %\n",
      "225.73419189453125 226.41999800000002 0.003028911366162855, 1\n",
      "Accuracy(in +- 1.5%): 25.27777777777778 %\n",
      "58.98350524902344 58.81999999999999 0.0027797560187596796, 1\n",
      "Accuracy(in +- 1.5%): 35.27777777777778 %\n",
      "149.00381469726562 148.419998 0.003933544705111992, 1\n",
      "Accuracy(in +- 1.5%): 26.944444444444443 %\n",
      "124.39566040039062 122.13999899999999 0.01846783542540095, 0\n",
      "Accuracy(in +- 1.5%): 30.833333333333332 %\n",
      "183.5971221923828 184.270004 0.003651607928641428, 1\n",
      "Accuracy(in +- 1.5%): 31.944444444444443 %\n",
      "4.77235746383667 4.87 0.020049802086926114, 2\n",
      "Accuracy(in +- 1.5%): 9.166666666666666 %\n",
      "655.8580932617188 663.539978 0.011577124201974261, 1\n",
      "Accuracy(in +- 1.5%): 18.333333333333332 %\n",
      "243.58584594726562 249.729996 0.024603172030381062, 2\n",
      "Accuracy(in +- 1.5%): 42.5 %\n",
      "236.7579803466797 237.46000700000002 0.0029563995309758884, 1\n",
      "\n",
      "Accuracy(in +- 1.5%): 23.88888888888889 %\n",
      "57.90294647216797 57.189999 0.012466296286663136, 1\n",
      "Accuracy(in +- 1.5%): 22.22222222222222 %\n",
      "77.41386413574219 77.889999 0.006112913986015272, 1\n",
      "Accuracy(in +- 1.5%): 29.72222222222222 %\n",
      "52.52763366699219 52.439999 0.0016711416602465468, 1\n",
      "Accuracy(in +- 1.5%): 15.0 %\n",
      "126.4723892211914 129.740005 0.02518587677569914, 2\n",
      "Accuracy(in +- 1.5%): 28.333333333333332 %\n",
      "83.7669448852539 84.800003 0.012182288658009806, 1\n",
      "Accuracy(in +- 1.5%): 32.77777777777778 %\n",
      "574.2307739257812 580.919983 0.011514854489381117, 1\n",
      "Accuracy(in +- 1.5%): 17.77777777777778 %\n",
      "136.7274627685547 136.0 0.005348990945255055, 1\n",
      "Accuracy(in +- 1.5%): 24.166666666666668 %\n",
      "3234.53076171875 3306.370117 0.0217275600550227, 2\n",
      "Accuracy(in +- 1.5%): 32.22222222222222 %\n",
      "498.5067138671875 499.549988 0.0020884279008580114, 1\n",
      "Accuracy(in +- 1.5%): 14.444444444444445 %\n",
      "314.0323791503906 320.019989 0.018710112041186854, 2\n",
      "Accuracy(in +- 1.5%): 37.5 %\n",
      "2359.4921875 2381.350098 0.009178789174408866, 1\n",
      "Accuracy(in +- 1.5%): 29.166666666666668 %\n",
      "224.2890625 226.41999800000002 0.009411427960528561, 1\n",
      "Accuracy(in +- 1.5%): 32.77777777777778 %\n",
      "59.08800506591797 58.81999999999999 0.004556359502175715, 1\n",
      "Accuracy(in +- 1.5%): 31.944444444444443 %\n",
      "148.81512451171875 148.419998 0.0026622188185096017, 1\n",
      "Accuracy(in +- 1.5%): 29.72222222222222 %\n",
      "122.43418884277344 122.13999899999999 0.002408628174079555, 1\n",
      "Accuracy(in +- 1.5%): 34.166666666666664 %\n",
      "180.0992889404297 184.270004 0.022633716660527735, 2\n",
      "Accuracy(in +- 1.5%): 36.111111111111114 %\n",
      "4.765927314758301 4.87 0.021370161240595344, 2\n",
      "Accuracy(in +- 1.5%): 3.611111111111111 %\n",
      "684.9768676757812 663.539978 0.032306854728474596, 0\n",
      "Accuracy(in +- 1.5%): 40.55555555555556 %\n",
      "246.20191955566406 249.729996 0.01412756377225881, 1\n",
      "Accuracy(in +- 1.5%): 11.38888888888889 %\n",
      "232.58441162109375 237.46000700000002 0.02053228011109369, 2\n",
      "\n",
      "Accuracy(in +- 1.5%): 25.0 %\n",
      "57.311092376708984 57.189999 0.0021173872849514145, 1\n",
      "Accuracy(in +- 1.5%): 33.05555555555556 %\n",
      "77.70217895507812 77.889999 0.002411349946504404, 1\n",
      "Accuracy(in +- 1.5%): 25.555555555555557 %\n",
      "52.610809326171875 52.439999 0.003257252658831568, 1\n",
      "Accuracy(in +- 1.5%): 36.666666666666664 %\n",
      "131.12100219726562 129.740005 0.01064434364146686, 1\n",
      "Accuracy(in +- 1.5%): 20.0 %\n",
      "86.35028839111328 84.800003 0.018281666701276855, 0\n",
      "Accuracy(in +- 1.5%): 38.888888888888886 %\n",
      "571.3113403320312 580.919983 0.016540389294834694, 2\n",
      "Accuracy(in +- 1.5%): 19.166666666666668 %\n",
      "136.8795623779297 136.0 0.006467370425953585, 1\n",
      "Accuracy(in +- 1.5%): 34.166666666666664 %\n",
      "3293.603515625 3306.370117 0.0038612136340572716, 1\n",
      "Accuracy(in +- 1.5%): 26.38888888888889 %\n",
      "505.8157958984375 499.549988 0.012542904712145675, 1\n",
      "Accuracy(in +- 1.5%): 22.22222222222222 %\n",
      "317.77362060546875 320.019989 0.007019462757781857, 1\n",
      "Accuracy(in +- 1.5%): 15.833333333333334 %\n",
      "2395.79052734375 2381.350098 0.006063967392227647, 1\n",
      "Accuracy(in +- 1.5%): 26.11111111111111 %\n",
      "228.94418334960938 226.41999800000002 0.011148243847300775, 1\n",
      "Accuracy(in +- 1.5%): 26.11111111111111 %\n",
      "57.62637710571289 58.81999999999999 0.020292806771287024, 2\n",
      "Accuracy(in +- 1.5%): 24.444444444444443 %\n",
      "147.6521759033203 148.419998 0.005173306205540308, 1\n",
      "Accuracy(in +- 1.5%): 28.88888888888889 %\n",
      "122.51812744140625 122.13999899999999 0.0030958608523180124, 1\n",
      "Accuracy(in +- 1.5%): 31.666666666666668 %\n",
      "181.63558959960938 184.270004 0.014296490710395952, 1\n",
      "Accuracy(in +- 1.5%): 31.11111111111111 %\n",
      "4.8395256996154785 4.87 0.00625755654712969, 1\n",
      "Accuracy(in +- 1.5%): 16.11111111111111 %\n",
      "655.1192626953125 663.539978 0.01269059225348969, 1\n",
      "Accuracy(in +- 1.5%): 38.888888888888886 %\n",
      "248.35218811035156 249.729996 0.005517190212298075, 1\n",
      "Accuracy(in +- 1.5%): 31.38888888888889 %\n",
      "238.19140625 237.46000700000002 0.0030800944514415905, 1\n",
      "\n",
      "Accuracy(in +- 1.5%): 16.944444444444443 %\n",
      "57.85954284667969 57.189999 0.011707358950639032, 1\n",
      "Accuracy(in +- 1.5%): 29.72222222222222 %\n",
      "76.79402923583984 77.889999 0.01407073794108226, 1\n",
      "Accuracy(in +- 1.5%): 26.11111111111111 %\n",
      "52.282958984375 52.439999 0.0029946609195206173, 1\n",
      "Accuracy(in +- 1.5%): 9.444444444444445 %\n",
      "126.64448547363281 129.740005 0.0238594065598131, 2\n",
      "Accuracy(in +- 1.5%): 33.611111111111114 %\n",
      "83.81952667236328 84.800003 0.011562220435731853, 1\n",
      "Accuracy(in +- 1.5%): 28.61111111111111 %\n",
      "569.0933837890625 580.919983 0.020358396262876537, 2\n",
      "Accuracy(in +- 1.5%): 12.777777777777779 %\n",
      "133.16632080078125 136.0 0.02083587646484375, 2\n",
      "Accuracy(in +- 1.5%): 35.27777777777778 %\n",
      "3295.685546875 3306.370117 0.003231510613425961, 1\n",
      "Accuracy(in +- 1.5%): 21.944444444444443 %\n",
      "506.86199951171875 499.549988 0.014637196851896963, 1\n",
      "Accuracy(in +- 1.5%): 12.222222222222221 %\n",
      "315.3634948730469 320.019989 0.014550635232204618, 1\n",
      "Accuracy(in +- 1.5%): 31.38888888888889 %\n",
      "2357.91015625 2381.350098 0.009843131326925072, 1\n",
      "Accuracy(in +- 1.5%): 25.555555555555557 %\n",
      "228.37478637695312 226.41999800000002 0.008633461682801992, 1\n",
      "Accuracy(in +- 1.5%): 30.0 %\n",
      "58.32328414916992 58.81999999999999 0.008444676144679895, 1\n",
      "Accuracy(in +- 1.5%): 26.11111111111111 %\n",
      "148.3797149658203 148.419998 0.0002714124425448385, 1\n",
      "Accuracy(in +- 1.5%): 25.27777777777778 %\n",
      "122.70806884765625 122.13999899999999 0.004650973082587475, 1\n",
      "Accuracy(in +- 1.5%): 25.0 %\n",
      "179.77325439453125 184.270004 0.024403047201696212, 2\n",
      "Accuracy(in +- 1.5%): 24.444444444444443 %\n",
      "4.8702802658081055 4.87 5.7549447249561016e-05, 1\n",
      "Accuracy(in +- 1.5%): 3.888888888888889 %\n",
      "690.7440185546875 663.539978 0.04099834442030783, 0\n",
      "Accuracy(in +- 1.5%): 40.833333333333336 %\n",
      "248.54449462890625 249.729996 0.00474713246338958, 1\n",
      "Accuracy(in +- 1.5%): 30.0 %\n",
      "232.67459106445312 237.46000700000002 0.0201525132421431, 2\n",
      "\n",
      "Accuracy(in +- 1.5%): 19.72222222222222 %\n",
      "58.07221984863281 57.189999 0.015426138556722343, 0\n",
      "Accuracy(in +- 1.5%): 13.88888888888889 %\n",
      "76.44422912597656 77.889999 0.018561688183144548, 2\n",
      "Accuracy(in +- 1.5%): 25.833333333333332 %\n",
      "52.171417236328125 52.439999 0.005121696582638669, 1\n",
      "Accuracy(in +- 1.5%): 39.166666666666664 %\n",
      "129.15977478027344 129.740005 0.00447225371793811, 1\n",
      "Accuracy(in +- 1.5%): 25.555555555555557 %\n",
      "83.30854034423828 84.800003 0.017588002393840983, 2\n",
      "Accuracy(in +- 1.5%): 33.611111111111114 %\n",
      "569.4198608398438 580.919983 0.019796396227871285, 2\n",
      "Accuracy(in +- 1.5%): 17.22222222222222 %\n",
      "137.69329833984375 136.0 0.012450723087086397, 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy(in +- 1.5%): 40.0 %\n",
      "3300.041015625 3306.370117 0.0019142144258013619, 1\n",
      "Accuracy(in +- 1.5%): 38.611111111111114 %\n",
      "501.15460205078125 499.549988 0.0032121190858306363, 1\n",
      "Accuracy(in +- 1.5%): 20.833333333333332 %\n",
      "322.3936767578125 320.019989 0.007417310916201832, 1\n",
      "Accuracy(in +- 1.5%): 16.11111111111111 %\n",
      "2319.663330078125 2381.350098 0.025904115473689957, 2\n",
      "Accuracy(in +- 1.5%): 30.555555555555557 %\n",
      "224.98147583007812 226.41999800000002 0.0063533353176776185, 1\n",
      "Accuracy(in +- 1.5%): 16.944444444444443 %\n",
      "56.87989807128906 58.81999999999999 0.03298371181079447, 2\n",
      "Accuracy(in +- 1.5%): 28.055555555555557 %\n",
      "147.29595947265625 148.419998 0.007573363040631106, 1\n",
      "Accuracy(in +- 1.5%): 33.333333333333336 %\n",
      "122.65020751953125 122.13999899999999 0.004177243521438552, 1\n",
      "Accuracy(in +- 1.5%): 34.72222222222222 %\n",
      "183.80531311035156 184.270004 0.0025217934528749325, 1\n",
      "Accuracy(in +- 1.5%): 21.11111111111111 %\n",
      "4.911104202270508 4.87 0.008440287940555997, 1\n",
      "Accuracy(in +- 1.5%): 4.722222222222222 %\n",
      "655.2496948242188 663.539978 0.012494022139810344, 1\n",
      "Accuracy(in +- 1.5%): 38.333333333333336 %\n",
      "247.45860290527344 249.729996 0.009095395551628338, 1\n",
      "Accuracy(in +- 1.5%): 23.61111111111111 %\n",
      "240.50454711914062 237.46000700000002 0.012821275285907855, 1\n",
      "\n",
      "Accuracy(in +- 1.5%): 25.833333333333332 %\n",
      "56.65704345703125 57.189999 0.009319033962017559, 1\n",
      "Accuracy(in +- 1.5%): 25.27777777777778 %\n",
      "77.14593505859375 77.889999 0.009552753254063504, 1\n",
      "Accuracy(in +- 1.5%): 28.88888888888889 %\n",
      "52.112083435058594 52.439999 0.006253157345434093, 1\n",
      "Accuracy(in +- 1.5%): 40.55555555555556 %\n",
      "128.24281311035156 129.740005 0.01153994012601151, 1\n",
      "Accuracy(in +- 1.5%): 10.277777777777779 %\n",
      "82.23484802246094 84.800003 0.030249468004606865, 2\n",
      "Accuracy(in +- 1.5%): 13.333333333333334 %\n",
      "564.8570556640625 580.919983 0.027650843155687246, 2\n",
      "Accuracy(in +- 1.5%): 16.944444444444443 %\n",
      "136.83883666992188 136.0 0.0061679166906020225, 1\n",
      "Accuracy(in +- 1.5%): 10.0 %\n",
      "3237.69189453125 3306.370117 0.02077148656638126, 2\n",
      "Accuracy(in +- 1.5%): 16.666666666666668 %\n",
      "487.73480224609375 499.549988 0.023651658568163623, 2\n",
      "Accuracy(in +- 1.5%): 20.0 %\n",
      "322.10406494140625 320.019989 0.006512330520098357, 1\n",
      "Accuracy(in +- 1.5%): 31.38888888888889 %\n",
      "2340.2744140625 2381.350098 0.01724890597648691, 2\n",
      "Accuracy(in +- 1.5%): 30.0 %\n",
      "227.96511840820312 226.41999800000002 0.006824134006940075, 1\n",
      "Accuracy(in +- 1.5%): 23.055555555555557 %\n",
      "59.092872619628906 58.81999999999999 0.004639112880464351, 1\n",
      "Accuracy(in +- 1.5%): 30.0 %\n",
      "148.50006103515625 148.419998 0.0005394356302056915, 1\n",
      "Accuracy(in +- 1.5%): 19.72222222222222 %\n",
      "123.53887939453125 122.13999899999999 0.011453089945835526, 1\n",
      "Accuracy(in +- 1.5%): 26.666666666666668 %\n",
      "185.5472869873047 184.270004 0.00693158386920471, 1\n",
      "Accuracy(in +- 1.5%): 29.72222222222222 %\n",
      "4.855804920196533 4.87 0.002914800780999364, 1\n",
      "Accuracy(in +- 1.5%): 13.88888888888889 %\n",
      "671.42041015625 663.539978 0.011876348701705477, 1\n",
      "Accuracy(in +- 1.5%): 21.11111111111111 %\n",
      "245.19052124023438 249.729996 0.018177531063451526, 2\n",
      "Accuracy(in +- 1.5%): 37.5 %\n",
      "240.74481201171875 237.46000700000002 0.013833087319494314, 1\n",
      "\n",
      "Accuracy(in +- 1.5%): 12.222222222222221 %\n",
      "58.28183364868164 57.189999 0.019091356317065863, 0\n",
      "Accuracy(in +- 1.5%): 20.27777777777778 %\n",
      "80.64790344238281 77.889999 0.03540768362807155, 0\n",
      "Accuracy(in +- 1.5%): 31.38888888888889 %\n",
      "51.657867431640625 52.439999 0.01491478991750887, 1\n",
      "Accuracy(in +- 1.5%): 22.77777777777778 %\n",
      "128.88787841796875 129.740005 0.006567955520205556, 1\n",
      "Accuracy(in +- 1.5%): 18.88888888888889 %\n",
      "86.04956817626953 84.800003 0.014735437878103936, 1\n",
      "Accuracy(in +- 1.5%): 35.833333333333336 %\n",
      "582.0992431640625 580.919983 0.0020299872591273867, 1\n",
      "Accuracy(in +- 1.5%): 14.444444444444445 %\n",
      "135.2724609375 136.0 0.0053495519301470585, 1\n",
      "Accuracy(in +- 1.5%): 36.94444444444444 %\n",
      "3314.283203125 3306.370117 0.002393285036153157, 1\n",
      "Accuracy(in +- 1.5%): 30.833333333333332 %\n",
      "507.59716796875 499.549988 0.016108858296579553, 0\n",
      "Accuracy(in +- 1.5%): 27.77777777777778 %\n",
      "318.6708679199219 320.019989 0.004215740036407959, 1\n",
      "Accuracy(in +- 1.5%): 20.0 %\n",
      "2367.67919921875 2381.350098 0.005740818535137495, 1\n",
      "Accuracy(in +- 1.5%): 28.333333333333332 %\n",
      "225.15682983398438 226.41999800000002 0.0055788719069578205, 1\n",
      "Accuracy(in +- 1.5%): 30.833333333333332 %\n",
      "58.57406234741211 58.81999999999999 0.004181190965451952, 1\n",
      "Accuracy(in +- 1.5%): 24.166666666666668 %\n",
      "147.72454833984375 148.419998 0.0046856870336047475, 1\n",
      "Accuracy(in +- 1.5%): 30.833333333333332 %\n",
      "122.66862487792969 122.13999899999999 0.004328032440295817, 1\n",
      "Accuracy(in +- 1.5%): 27.22222222222222 %\n",
      "183.48719787597656 184.270004 0.004248147322032063, 1\n",
      "Accuracy(in +- 1.5%): 33.05555555555556 %\n",
      "4.838996887207031 4.87 0.006366142257283132, 1\n",
      "Accuracy(in +- 1.5%): 11.38888888888889 %\n",
      "677.502685546875 663.539978 0.02104275252406115, 0\n",
      "Accuracy(in +- 1.5%): 31.666666666666668 %\n",
      "252.04501342773438 249.729996 0.009270081547329922, 1\n",
      "Accuracy(in +- 1.5%): 32.77777777777778 %\n",
      "239.2850799560547 237.46000700000002 0.007685811935711215, 1\n",
      "\n",
      "Accuracy(in +- 1.5%): 21.38888888888889 %\n",
      "58.173126220703125 57.189999 0.017190544463956448, 0\n",
      "Accuracy(in +- 1.5%): 28.88888888888889 %\n",
      "78.7210464477539 77.889999 0.01066950132781364, 1\n",
      "Accuracy(in +- 1.5%): 16.38888888888889 %\n",
      "51.067222595214844 52.439999 0.026178040254828314, 2\n",
      "Accuracy(in +- 1.5%): 9.166666666666666 %\n",
      "132.4560089111328 129.740005 0.020934205383550095, 0\n",
      "Accuracy(in +- 1.5%): 31.11111111111111 %\n",
      "84.0737533569336 84.800003 0.008564264355820955, 1\n",
      "Accuracy(in +- 1.5%): 30.0 %\n",
      "574.7275390625 580.919983 0.01065971927066589, 1\n",
      "Accuracy(in +- 1.5%): 19.444444444444443 %\n",
      "134.67471313476562 136.0 0.009744756362017463, 1\n",
      "Accuracy(in +- 1.5%): 10.0 %\n",
      "3225.3271484375 3306.370117 0.024511160485576073, 2\n",
      "Accuracy(in +- 1.5%): 27.77777777777778 %\n",
      "510.7373046875 499.549988 0.02239478922277547, 0\n",
      "Accuracy(in +- 1.5%): 16.38888888888889 %\n",
      "313.84844970703125 320.019989 0.019284855649966164, 2\n",
      "Accuracy(in +- 1.5%): 28.61111111111111 %\n",
      "2322.177001953125 2381.350098 0.024848549609136426, 2\n",
      "Accuracy(in +- 1.5%): 16.11111111111111 %\n",
      "233.41827392578125 226.41999800000002 0.03090838259693487, 0\n",
      "Accuracy(in +- 1.5%): 33.611111111111114 %\n",
      "58.68295669555664 58.81999999999999 0.0023298759680950793, 1\n",
      "Accuracy(in +- 1.5%): 18.88888888888889 %\n",
      "146.0916748046875 148.419998 0.015687395409562616, 2\n",
      "Accuracy(in +- 1.5%): 20.833333333333332 %\n",
      "120.92431640625 122.13999899999999 0.00995318981253626, 1\n",
      "Accuracy(in +- 1.5%): 30.833333333333332 %\n",
      "184.10513305664062 184.270004 0.000894724804799891, 1\n",
      "Accuracy(in +- 1.5%): 31.666666666666668 %\n",
      "4.864250183105469 4.87 0.0011806605532918596, 1\n",
      "Accuracy(in +- 1.5%): 6.388888888888889 %\n",
      "681.6524658203125 663.539978 0.0272967544094419, 0\n",
      "Accuracy(in +- 1.5%): 10.833333333333334 %\n",
      "250.94598388671875 249.729996 0.004869210371984109, 1\n",
      "Accuracy(in +- 1.5%): 17.5 %\n",
      "240.51678466796875 237.46000700000002 0.012872810485383045, 1\n",
      "\n",
      "Accuracy(in +- 1.5%): 25.555555555555557 %\n",
      "57.5836181640625 57.189999 0.006882657299268352, 1\n",
      "Accuracy(in +- 1.5%): 13.88888888888889 %\n",
      "80.25676727294922 77.889999 0.030386035477407255, 0\n",
      "Accuracy(in +- 1.5%): 18.333333333333332 %\n",
      "52.522560119628906 52.439999 0.0015743920900705205, 1\n",
      "Accuracy(in +- 1.5%): 39.44444444444444 %\n",
      "129.7880401611328 129.740005 0.0003702417086604554, 1\n",
      "Accuracy(in +- 1.5%): 25.0 %\n",
      "83.35401916503906 84.800003 0.017051695563748286, 2\n",
      "Accuracy(in +- 1.5%): 34.72222222222222 %\n",
      "580.73828125 580.919983 0.00031278275032243466, 1\n",
      "Accuracy(in +- 1.5%): 12.222222222222221 %\n",
      "135.7250213623047 136.0 0.0020219017477596506, 1\n",
      "Accuracy(in +- 1.5%): 20.0 %\n",
      "3254.9560546875 3306.370117 0.015550002115053575, 2\n",
      "Accuracy(in +- 1.5%): 38.611111111111114 %\n",
      "501.00286865234375 499.549988 0.0029083789155125855, 1\n",
      "Accuracy(in +- 1.5%): 23.055555555555557 %\n",
      "318.61090087890625 320.019989 0.0044031253344420295, 1\n",
      "Accuracy(in +- 1.5%): 33.611111111111114 %\n",
      "2367.61328125 2381.350098 0.005768499458159004, 1\n",
      "Accuracy(in +- 1.5%): 37.22222222222222 %\n",
      "227.45828247070312 226.41999800000002 0.004585657096874914, 1\n",
      "Accuracy(in +- 1.5%): 27.22222222222222 %\n",
      "59.6493034362793 58.81999999999999 0.014099004357009585, 1\n",
      "Accuracy(in +- 1.5%): 28.61111111111111 %\n",
      "146.90252685546875 148.419998 0.010224169013472447, 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy(in +- 1.5%): 31.11111111111111 %\n",
      "122.83778381347656 122.13999899999999 0.0057129918060386895, 1\n",
      "Accuracy(in +- 1.5%): 35.833333333333336 %\n",
      "182.87808227539062 184.270004 0.007553707572554105, 1\n",
      "Accuracy(in +- 1.5%): 25.833333333333332 %\n",
      "4.729892253875732 4.87 0.028769557725722317, 2\n",
      "Accuracy(in +- 1.5%): 12.222222222222221 %\n",
      "680.0805053710938 663.539978 0.02492770280541217, 0\n",
      "Accuracy(in +- 1.5%): 41.111111111111114 %\n",
      "248.23944091796875 249.729996 0.005968666583533881, 1\n",
      "Accuracy(in +- 1.5%): 27.77777777777778 %\n",
      "237.25648498535156 237.46000700000002 0.0008570791234266922, 1\n",
      "\n",
      "Accuracy(in +- 1.5%): 22.5 %\n",
      "57.551422119140625 57.189999 0.006319690950521345, 1\n",
      "Accuracy(in +- 1.5%): 35.0 %\n",
      "77.69246673583984 77.889999 0.0025360414263217454, 1\n",
      "Accuracy(in +- 1.5%): 26.666666666666668 %\n",
      "52.35978698730469 52.439999 0.0015295959997122187, 1\n",
      "Accuracy(in +- 1.5%): 4.722222222222222 %\n",
      "126.2474136352539 129.740005 0.02691992623821843, 2\n",
      "Accuracy(in +- 1.5%): 31.666666666666668 %\n",
      "85.3049087524414 84.800003 0.005954077058716642, 1\n",
      "Accuracy(in +- 1.5%): 40.27777777777778 %\n",
      "582.8968505859375 580.919983 0.0034029946357302327, 1\n",
      "Accuracy(in +- 1.5%): 12.5 %\n",
      "136.07801818847656 136.0 0.0005736631505629595, 1\n",
      "Accuracy(in +- 1.5%): 37.22222222222222 %\n",
      "3319.001953125 3306.370117 0.0038204543587096735, 1\n",
      "Accuracy(in +- 1.5%): 19.166666666666668 %\n",
      "490.44305419921875 499.549988 0.01823027528684724, 2\n",
      "Accuracy(in +- 1.5%): 31.666666666666668 %\n",
      "319.21380615234375 320.019989 0.0025191640377697144, 1\n",
      "Accuracy(in +- 1.5%): 36.111111111111114 %\n",
      "2393.156982421875 2381.350098 0.004958063256549819, 1\n",
      "Accuracy(in +- 1.5%): 29.166666666666668 %\n",
      "226.78021240234375 226.41999800000002 0.0015909124879672908, 1\n",
      "Accuracy(in +- 1.5%): 31.38888888888889 %\n",
      "58.6009635925293 58.81999999999999 0.0037238423575432903, 1\n",
      "Accuracy(in +- 1.5%): 35.0 %\n",
      "147.33538818359375 148.419998 0.0073077067175694385, 1\n",
      "Accuracy(in +- 1.5%): 24.166666666666668 %\n",
      "122.50227355957031 122.13999899999999 0.002966059951992661, 1\n",
      "Accuracy(in +- 1.5%): 33.888888888888886 %\n",
      "181.6560821533203 184.270004 0.014185281325981236, 1\n",
      "Accuracy(in +- 1.5%): 31.944444444444443 %\n",
      "4.880978584289551 4.87 0.0022543294229056825, 1\n",
      "Accuracy(in +- 1.5%): 12.777777777777779 %\n",
      "660.4000244140625 663.539978 0.0047321241975529, 1\n",
      "Accuracy(in +- 1.5%): 15.277777777777779 %\n",
      "243.5078125 249.729996 0.02491564329340717, 2\n",
      "Accuracy(in +- 1.5%): 40.55555555555556 %\n",
      "239.60543823242188 237.46000700000002 0.009034916066610981, 1\n",
      "\n",
      "[4 6 0]\n",
      "[2 7 1]\n",
      "[0 9 1]\n",
      "[1 6 3]\n",
      "[1 6 3]\n",
      "[0 6 4]\n",
      "[0 8 2]\n",
      "[0 5 5]\n",
      "[3 5 2]\n",
      "[0 8 2]\n",
      "[0 6 4]\n",
      "[1 9 0]\n",
      "[0 8 2]\n",
      "[0 9 1]\n",
      "[1 9 0]\n",
      "[0 8 2]\n",
      "[0 7 3]\n",
      "[5 5 0]\n",
      "[0 7 3]\n",
      "[0 8 2]\n"
     ]
    }
   ],
   "source": [
    "# Hyper-parameters\n",
    "NUM_FEATURES = 7\n",
    "TEST_SIZE = 360\n",
    "NUM_EPOCHS = 100\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.005\n",
    "DROP_OUT = 0.0\n",
    "\n",
    "INPUT_SIZE = NUM_FEATURES # open, high, low, close, adj. close,volume\n",
    "SEQ_LENGTH = 10\n",
    "HIDDEN_SIZE = 128\n",
    "NUM_LAYERS = 1\n",
    "ACC = 0.015\n",
    "FILE_PREFIX = 'data\\\\0507\\\\'\n",
    "FILE_NAME = ['INTC.csv','AMD.csv','CSCO.csv','AAPL.csv','MU.csv','NVDA.csv','QCOM.csv','AMZN.csv','NFLX.csv','FB.csv',\n",
    "             'GOOG.csv','BABA.csv','EBAY.csv','IBM.csv','XLNX.csv','TXN.csv','NOK.csv','TSLA.csv','MSFT.csv','SNPS.csv']\n",
    "\n",
    "# Preprocess\n",
    "ary = np.array([0]*60)\n",
    "ary = ary.reshape(20,3)\n",
    "for t in range(10):\n",
    "    for i in range(20):\n",
    "        sp1 = StockPrediction(FILE_NAME[i])\n",
    "        sp1.getFeatures()\n",
    "        sp1.getLabels()\n",
    "        sp1.shuffleData()\n",
    "        sp1.splitTrainTest(TEST_SIZE)\n",
    "        sp1.toTensor()\n",
    "        sp1.train()\n",
    "        sp1.test()\n",
    "        #sp1.testResult()\n",
    "        #sp1.plotGraph()\n",
    "        ans = sp1.predict()\n",
    "        ary[i][ans] += 1\n",
    "    print('')\n",
    "for i in range(20):\n",
    "    print(ary[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30b830c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
